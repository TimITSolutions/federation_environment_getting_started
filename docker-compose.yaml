services:
  mlflow-server:
    restart: always
    build: 
      dockerfile: mlflow
      context: docker_scripts
    container_name: mlflow_server
    working_dir: /app
    command: mlflow server --default-artifact-root /tmp/ --no-serve-artifacts --host 0.0.0.0 --port 3001 
    ports:
      - "3001:3001" 

  submission_run:
    build: 
      dockerfile: execute_code 
      context: docker_scripts
    container_name: code_submission 
    network_mode: "host"
    working_dir: /app
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command: python3 main.py
    depends_on:
      - mlflow-server
    volumes:
      - export:/mnt/export/
      - '/home/dataset:/mnt/dataset/' #replace the left side of the colon with your local path to the CLaM dataset, e.g. if your local path is: /home/dataset/CLaM-sample, then use /home/dataset

volumes:
  export:
